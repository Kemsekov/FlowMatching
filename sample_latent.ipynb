{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kemsekov_torch.common_modules import Residual\n",
    "from kemsekov_torch.residual import ResidualBlock\n",
    "from kemsekov_torch.attention import LinearSelfAttentionBlock, EfficientSpatialChannelAttention\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class TimeContextEmbedding(nn.Module):\n",
    "    def __init__(self,input_dim,context_dim,internal_dim) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        def norm(ch):\n",
    "            return nn.GroupNorm(16,ch)\n",
    "        \n",
    "        self.input_2_internal = Residual([\n",
    "            nn.Conv2d(input_dim,internal_dim,1)\n",
    "        ])\n",
    "        self.context_2_internal = Residual([\n",
    "            nn.Linear(context_dim,internal_dim)\n",
    "        ])\n",
    "        self.time = nn.Sequential(\n",
    "            nn.Linear(1,internal_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(internal_dim,internal_dim),\n",
    "        )\n",
    "        self.context_norm = nn.RMSNorm(internal_dim)\n",
    "        \n",
    "        self.output = Residual([\n",
    "            nn.Conv2d(internal_dim,input_dim,1)\n",
    "        ])\n",
    "        \n",
    "    def forward(self,x,context,time):\n",
    "        x = self.input_2_internal(x)\n",
    "        context = self.context_2_internal(context)\n",
    "        context=(context+self.time(time))\n",
    "        context=self.context_norm(context)\n",
    "        if context.ndim>2:\n",
    "            context=context[0]\n",
    "        while context.ndim!=x.ndim:\n",
    "            context=context.unsqueeze(-1)\n",
    "        x+=context\n",
    "        return self.output(x)\n",
    "\n",
    "class FlowMatchingModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels, \n",
    "        context_dim,\n",
    "        expand_dim = 128,\n",
    "        residual_block_repeats = 1,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.context_dim=context_dim\n",
    "        self.expand = nn.Conv2d(in_channels,expand_dim,1)\n",
    "        norm='group'\n",
    "        def down_block(in_ch,out_ch):\n",
    "            return nn.Sequential(\n",
    "                ResidualBlock(\n",
    "                    in_ch,\n",
    "                    residual_block_repeats*[out_ch],\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    normalization=norm\n",
    "                ),\n",
    "                EfficientSpatialChannelAttention(out_ch)\n",
    "            )\n",
    "        def up_block(in_ch,out_ch):\n",
    "            return nn.Sequential(\n",
    "                ResidualBlock(\n",
    "                    in_ch,\n",
    "                    residual_block_repeats*[out_ch],\n",
    "                    kernel_size=4,\n",
    "                    stride=2,\n",
    "                    normalization=norm\n",
    "                ).transpose(),\n",
    "                EfficientSpatialChannelAttention(out_ch)\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.down1 = down_block(expand_dim,expand_dim*2)\n",
    "        self.attn1 = TimeContextEmbedding(expand_dim*2,context_dim,expand_dim*2)\n",
    "        \n",
    "        self.down2 = down_block(expand_dim*2,expand_dim*4)\n",
    "        self.attn2 = TimeContextEmbedding(expand_dim*4,context_dim,expand_dim*4)\n",
    "        \n",
    "        self.down3 = down_block(expand_dim*4,expand_dim*8)\n",
    "        \n",
    "        self.attn3_1 = TimeContextEmbedding(expand_dim*8,context_dim,expand_dim*8)\n",
    "        self.attn3_2 = LinearSelfAttentionBlock(expand_dim*8,mlp_dim=expand_dim*8,heads=16,add_gating=True)\n",
    "        \n",
    "        self.up1 = up_block(expand_dim*8,expand_dim*4)\n",
    "        self.up1_combine=nn.Sequential(\n",
    "            nn.Conv2d(8*expand_dim,4*expand_dim,1)\n",
    "        )\n",
    "        \n",
    "        self.up2 = up_block(expand_dim*4,expand_dim*2)\n",
    "        self.up2_combine=nn.Sequential(\n",
    "            nn.Conv2d(4*expand_dim,2*expand_dim,1)\n",
    "        )\n",
    "        \n",
    "        self.up3 = up_block(expand_dim*2,expand_dim)\n",
    "        self.up3_combine=nn.Sequential(\n",
    "            nn.Conv2d(2*expand_dim,expand_dim,1)\n",
    "        )\n",
    "        \n",
    "        self.final = ResidualBlock(\n",
    "            expand_dim,\n",
    "            [expand_dim,in_channels],\n",
    "            3,\n",
    "            normalization=norm\n",
    "        )\n",
    "\n",
    "    def forward(self,x, context : torch.Tensor, time):\n",
    "        if time.dim()<2:\n",
    "            time = time[:,None]\n",
    "        orig_x=x\n",
    "        # make it wider\n",
    "        time=time*5-2.5\n",
    "        \n",
    "        x=self.expand(x)\n",
    "        \n",
    "        d1 = self.down1(x)\n",
    "        d1 = self.attn1(d1,context,time)\n",
    "        \n",
    "        d2 = self.down2(d1)\n",
    "        d2 = self.attn2(d2,context,time)\n",
    "        \n",
    "        d3 = self.down3(d2)\n",
    "        d3 = self.attn3_1(d3,context,time)\n",
    "        d3 = self.attn3_2(d3.transpose(1,-1)).transpose(1,-1)\n",
    "        \n",
    "        u1 = self.up1(d3)\n",
    "        u1 = self.up1_combine(torch.concat([u1,d2],1))\n",
    "        u2 = self.up2(u1)\n",
    "        u2 = self.up2_combine(torch.concat([u2,d1],1))\n",
    "        u3 = self.up3(u2)\n",
    "        u3 = self.up3_combine(torch.concat([u3,x],1))\n",
    "        \n",
    "        return self.final(u3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d176ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kemsekov_torch.train import load_best_checkpoint, load_last_checkpoint\n",
    "from kemsekov_torch.flow_matching import FlowMatching\n",
    "from kemsekov_torch.common_modules import wrap_submodules,CheapSequential\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = FlowMatchingModel(\n",
    "        4,\n",
    "        512,\n",
    "        expand_dim=128,\n",
    "        residual_block_repeats=1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "fm = FlowMatching()\n",
    "model = get_model()\n",
    "path = 'runs/vae-tree/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930985eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip_emb import CLIPEmbedder\n",
    "c=CLIPEmbedder(device='cpu')\n",
    "embedds_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f505b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt\n",
    "from vae import decode\n",
    "\n",
    "def sample(\n",
    "    guidance,\n",
    "    reference_image,\n",
    "    images_count,\n",
    "    image_shape, \n",
    "    steps = 32,\n",
    "    churn_scale=0.001,\n",
    "    random_state=None,\n",
    "    device='cuda',\n",
    "    dtype=torch.bfloat16\n",
    "):\n",
    "    image_shape = [v//8 for v in image_shape]\n",
    "    if random_state is not None:\n",
    "        g = torch.Generator(device)\n",
    "        g.manual_seed(random_state)\n",
    "    else:\n",
    "        g = None\n",
    "        \n",
    "    x0 = torch.randn([images_count,4]+image_shape,generator=g,device=device)\n",
    "    if reference_image in embedds_cache:\n",
    "        clip_emb=embedds_cache[reference_image].to(device)\n",
    "    else:\n",
    "        if reference_image is None:\n",
    "            clip_emb=torch.zeros((1,512)).to(device)\n",
    "        else:\n",
    "            print(\"compute\")\n",
    "            clip_emb = c.image_to_embedding(reference_image)[None,:].to(device)\n",
    "            embedds_cache[reference_image]=clip_emb.cpu()\n",
    "    context=clip_emb[[0]*images_count]\n",
    "    \n",
    "    m = model.to(device)\n",
    "    def run_model(xt,t):\n",
    "        pred_no_cls = m(xt,(context*0).to(dtype),t)\n",
    "        if guidance==0:\n",
    "            return pred_no_cls.float()\n",
    "        pred_cls =  m(xt,context,t)\n",
    "        total = pred_no_cls+guidance*(pred_cls-pred_no_cls)\n",
    "        return total\n",
    "\n",
    "    with torch.autocast(device,dtype=dtype):\n",
    "        sample = fm.sample(\n",
    "            run_model,\n",
    "            x0,\n",
    "            steps,\n",
    "            churn_scale=churn_scale,\n",
    "            device=device,\n",
    "        )\n",
    "        sample_dec = decode(sample,device).clip(0,1).to(device)\n",
    "    return sample_dec\n",
    "\n",
    "\n",
    "\n",
    "model = load_last_checkpoint(model,path).eval()\n",
    "images_count=4\n",
    "sample_dec = sample(\n",
    "    guidance=0,\n",
    "    reference_image='/home/vlad/Documents/TreesDataset/Fir/2c22efd.png',\n",
    "    images_count=images_count,\n",
    "    image_shape=(256+256,256),\n",
    "    steps=32,\n",
    "    device='cuda',\n",
    "    # churn_scale=0.01,\n",
    "    # random_state=113\n",
    ")\n",
    "\n",
    "sq = int(images_count**0.5)\n",
    "plt.figure(figsize=(8,6))\n",
    "for i,v in enumerate(sample_dec):\n",
    "    plt.subplot(1,images_count,1+i)\n",
    "    plt.imshow(T.ToPILImage()(v))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog\n",
    "from tkinter import Canvas\n",
    "from PIL import Image, ImageTk\n",
    "from tkinter import messagebox\n",
    "\n",
    "class ImageGeneratorApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Image Generator\")\n",
    "\n",
    "        # Main frame split: left (canvas) and right (controls)\n",
    "        self.main_frame = tk.Frame(root)\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Left: image canvas with scrollbar\n",
    "        self.canvas_frame = tk.Frame(self.main_frame)\n",
    "        self.canvas_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.canvas = Canvas(self.canvas_frame, bg=\"white\")\n",
    "        self.scrollbar = ttk.Scrollbar(self.canvas_frame, orient=tk.HORIZONTAL, command=self.canvas.xview)\n",
    "        self.canvas.configure(xscrollcommand=self.scrollbar.set)\n",
    "\n",
    "        self.scrollbar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.images_container = tk.Frame(self.canvas)\n",
    "        self.image_container = self.canvas.create_window((0, 0), window=self.images_container, anchor=\"nw\")\n",
    "\n",
    "        # --- Right ---\n",
    "        self.controls_frame = tk.Frame(self.main_frame, padx=10, pady=10)\n",
    "        self.controls_frame.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.fixed_controls = tk.Frame(self.controls_frame, padx=5, pady=5)\n",
    "        self.fixed_controls.pack(side=tk.TOP, fill=tk.X)\n",
    "\n",
    "        length = 300\n",
    "\n",
    "        # Guidance\n",
    "        tk.Label(self.fixed_controls, text=\"Guidance\").pack(anchor=\"w\")\n",
    "        self.guidance_slider = tk.Scale(self.fixed_controls, from_=0, to=5, resolution=0.1,\n",
    "                                        orient=tk.HORIZONTAL, length=length)\n",
    "        self.guidance_slider.set(1)\n",
    "        self.guidance_slider.pack(anchor=\"w\")\n",
    "\n",
    "        # Images count (scrollable 1–8)\n",
    "        tk.Label(self.fixed_controls, text=\"Images Count\").pack(anchor=\"w\")\n",
    "        self.images_count_slider = tk.Scale(self.fixed_controls, from_=1, to=8, resolution=1,\n",
    "                                            orient=tk.HORIZONTAL, length=length)\n",
    "        self.images_count_slider.set(1)\n",
    "        self.images_count_slider.pack(anchor=\"w\")\n",
    "\n",
    "        # Width (scrollable, auto-adjust to divisible by 32)\n",
    "        tk.Label(self.fixed_controls, text=\"Width\").pack(anchor=\"w\")\n",
    "        self.width_slider = tk.Scale(self.fixed_controls, from_=128, to=512, resolution=64,\n",
    "                                     orient=tk.HORIZONTAL, length=length)\n",
    "        self.width_slider.set(512)\n",
    "        self.width_slider.pack(anchor=\"w\")\n",
    "\n",
    "        # Height (scrollable, auto-adjust)\n",
    "        tk.Label(self.fixed_controls, text=\"Height\").pack(anchor=\"w\")\n",
    "        self.height_slider = tk.Scale(self.fixed_controls, from_=128, to=512, resolution=64,\n",
    "                                      orient=tk.HORIZONTAL, length=length)\n",
    "        self.height_slider.set(256)\n",
    "        self.height_slider.pack(anchor=\"w\")\n",
    "\n",
    "        # Steps (scrollable 4–32)\n",
    "        tk.Label(self.fixed_controls, text=\"Steps\").pack(anchor=\"w\")\n",
    "        self.steps_slider = tk.Scale(self.fixed_controls, from_=4, to=32, resolution=1,\n",
    "                                     orient=tk.HORIZONTAL, length=length)\n",
    "        self.steps_slider.set(24)\n",
    "        self.steps_slider.pack(anchor=\"w\")\n",
    "\n",
    "        # Smoothness (scrollable 0–0.01)\n",
    "        tk.Label(self.fixed_controls, text=\"Smoothness\").pack(anchor=\"w\")\n",
    "        self.smoothness_slider = tk.Scale(self.fixed_controls, from_=0, to=0.01, resolution=0.0001,\n",
    "                                          orient=tk.HORIZONTAL, length=length)\n",
    "        self.smoothness_slider.set(0.001)\n",
    "        self.smoothness_slider.pack(anchor=\"w\")\n",
    "\n",
    "        # Reference Image selection\n",
    "        tk.Label(self.fixed_controls, text=\"Reference Image\").pack(anchor=\"w\")\n",
    "        self.reference_image_path_var = tk.StringVar()\n",
    "        self.reference_image_entry = tk.Entry(self.fixed_controls,\n",
    "                                              textvariable=self.reference_image_path_var, width=40)\n",
    "        self.reference_image_entry.pack(anchor=\"w\")\n",
    "\n",
    "        self.ref_button = tk.Button(self.fixed_controls, text=\"Select Image\",\n",
    "                                    command=self.select_reference_image)\n",
    "        self.ref_button.pack(anchor=\"w\", pady=5)\n",
    "\n",
    "        self.path_to_referenec_image = None\n",
    "\n",
    "        # Generate / Save\n",
    "        self.generate_btn = tk.Button(self.fixed_controls, text=\"Generate\", command=self.generate_image)\n",
    "        self.generate_btn.pack(pady=5, fill=tk.X)\n",
    "\n",
    "        self.save_btn = tk.Button(self.fixed_controls, text=\"Save\", command=self.save_images)\n",
    "        self.save_btn.pack(pady=5, fill=tk.X)\n",
    "\n",
    "        # Container for images\n",
    "        self.generated_images = []\n",
    "        self.pil_images = []\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    def select_reference_image(self):\n",
    "        filetypes = [\n",
    "            (\"Image files\", \"*.png *.jpg *.jpeg *.webp\"),\n",
    "            (\"PNG files\", \"*.png\"),\n",
    "            (\"JPEG files\", \"*.jpg *.jpeg\"),\n",
    "            (\"WebP files\", \"*.webp\"),\n",
    "            (\"All files\", \"*.*\")\n",
    "        ]\n",
    "\n",
    "        filepath = filedialog.askopenfilename(\n",
    "            title=\"Select reference image\",\n",
    "            filetypes=filetypes\n",
    "        )\n",
    "\n",
    "        if filepath:\n",
    "            self.path_to_referenec_image = filepath\n",
    "            self.reference_image_path_var.set(filepath)\n",
    "            print(f\"Selected reference image: {filepath}\")\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    def generate_image(self):\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "        except: pass\n",
    "        for w in self.images_container.winfo_children():\n",
    "            w.destroy()\n",
    "        self.generated_images.clear()\n",
    "        self.pil_images.clear()\n",
    "\n",
    "        guidance = self.guidance_slider.get()\n",
    "        count = int(self.images_count_slider.get())\n",
    "        churn_scale = float(self.smoothness_slider.get())\n",
    "        steps = int(self.steps_slider.get())\n",
    "\n",
    "        width = int(self.width_slider.get())\n",
    "        height = int(self.height_slider.get())\n",
    "\n",
    "        # Always divisible by 32 because resolution=32 ensures it\n",
    "        try:\n",
    "            samples = sample(\n",
    "                guidance=guidance,\n",
    "                reference_image=self.path_to_referenec_image,\n",
    "                images_count=count,\n",
    "                image_shape=(width, height),\n",
    "                steps=steps,\n",
    "                churn_scale=churn_scale\n",
    "            )\n",
    "        except torch.OutOfMemoryError:\n",
    "            messagebox.showwarning(\n",
    "                \"Out of VRAM\",\n",
    "                \"Not enough GPU memory to generate the images.\\n\\n\"\n",
    "                \"Try lowering width/height, steps, or image count.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        for i, s in enumerate(samples):\n",
    "            img = T.ToPILImage()(s)\n",
    "            self.pil_images.append(img)\n",
    "            tk_img = ImageTk.PhotoImage(img)\n",
    "            self.generated_images.append(tk_img)\n",
    "\n",
    "            lbl = tk.Label(self.images_container, image=tk_img)\n",
    "\n",
    "            # Layout selection\n",
    "            if height > width:\n",
    "                # Vertical (top → down)\n",
    "                lbl.grid(row=i%4, column=i//4, padx=5, pady=5)\n",
    "            else:\n",
    "                # Horizontal (left → right)\n",
    "                lbl.grid(row=i//4, column=i%4, padx=5, pady=5)\n",
    "\n",
    "        self.canvas.update_idletasks()\n",
    "        self.canvas.config(scrollregion=self.canvas.bbox(\"all\"))\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    def save_images(self):\n",
    "        if not self.pil_images:\n",
    "            print(\"No images to save!\")\n",
    "            return\n",
    "\n",
    "        folder = filedialog.askdirectory(title=\"Select folder to save images\")\n",
    "        if not folder:\n",
    "            return\n",
    "\n",
    "        for idx, img in enumerate(self.pil_images):\n",
    "            path = os.path.join(folder, f\"image_{idx+1}.png\")\n",
    "            img.save(path)\n",
    "            print(f\"Saved {path}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    root.geometry(\"1600x1200\")\n",
    "    app = ImageGeneratorApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
