{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kemsekov_torch.common_modules import Residual\n",
    "from kemsekov_torch.residual import ResidualBlock\n",
    "from kemsekov_torch.attention import LinearSelfAttentionBlock,LinearCrossAttentionBlock, EfficientSpatialChannelAttention\n",
    "from kemsekov_torch.attention import MultiHeadLinearAttention\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self,in_channels,context_channels,internal_dim=128):\n",
    "        super().__init__()\n",
    "        def norm(ch):\n",
    "            # return nn.Identity()\n",
    "            return nn.RMSNorm(ch)\n",
    "            # return nn.LayerNorm(ch)\n",
    "        \n",
    "        self.input_2_internal = Residual([\n",
    "            nn.Linear(in_channels,internal_dim)\n",
    "            # norm(internal_dim)\n",
    "        ])\n",
    "        \n",
    "        self.context_2_internal = nn.Linear(context_channels,internal_dim)\n",
    "        self.time = nn.Sequential(\n",
    "            nn.Linear(1,internal_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(internal_dim,internal_dim),\n",
    "        )\n",
    "        self.context_norm = norm(internal_dim)\n",
    "\n",
    "        self.sa_QKV =nn.Sequential(\n",
    "            nn.Linear(\n",
    "                internal_dim,\n",
    "                internal_dim*3,\n",
    "            )\n",
    "        )\n",
    "        self.sa_norm = norm(internal_dim)\n",
    "        self.lsa = MultiHeadLinearAttention(\n",
    "            internal_dim,\n",
    "            n_heads=max(4,internal_dim//16),\n",
    "            dropout=0,\n",
    "            use_classic_attention=True,\n",
    "            add_rotary_emb=True\n",
    "        )\n",
    "        \n",
    "        self.cross_norm = norm(internal_dim)\n",
    "        self.lca = MultiHeadLinearAttention(\n",
    "            internal_dim,\n",
    "            n_heads=max(4,internal_dim//16),\n",
    "            dropout=0,\n",
    "            use_classic_attention=True\n",
    "        )\n",
    "        \n",
    "        self.cross_Q = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                internal_dim,\n",
    "                internal_dim,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.cross_KV = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                internal_dim,\n",
    "                internal_dim*2,\n",
    "            )\n",
    "        )\n",
    "        self.mlp_norm = norm(internal_dim)\n",
    "        self.mlp = Residual([\n",
    "            nn.Linear(internal_dim,4*internal_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*internal_dim,in_channels),\n",
    "        ],init_at_zero=True)\n",
    "        \n",
    "    def forward(self,x,context,time):\n",
    "        x_input = x\n",
    "        x,context = x.transpose(1,-1),context.transpose(1,-1)\n",
    "        x = self.input_2_internal(x)\n",
    "        context = self.context_2_internal(context)\n",
    "        context=context+self.time(time)\n",
    "        \n",
    "        q,k,v = self.sa_QKV(self.sa_norm(x)).chunk(3,-1)\n",
    "        x = self.lsa(q,k,v)[0]+x\n",
    "         \n",
    "        q = self.cross_Q(self.cross_norm(x))\n",
    "        k,v = self.cross_KV(self.context_norm(context)).chunk(2,-1)\n",
    "        x = self.lca(q,k,v)[0]+x\n",
    "        \n",
    "        return self.mlp(self.mlp_norm(x)).transpose(1,-1)+x_input\n",
    "\n",
    "class FlowMatchingModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels, \n",
    "        context_dim,\n",
    "        expand_dim = 128,\n",
    "        residual_block_repeats = 1,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        norm = 'batch'\n",
    "        self.context_dim=context_dim\n",
    "        self.expand = nn.Conv2d(in_channels,expand_dim,1)\n",
    "        \n",
    "        self.down1 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim,residual_block_repeats*[expand_dim*2],4,stride=2,normalization=norm),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*2)\n",
    "        )\n",
    "        \n",
    "        self.down2 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*2,residual_block_repeats*[expand_dim*4],4,stride=2,normalization=norm),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*4)\n",
    "        )\n",
    "        \n",
    "        self.down3 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*4,residual_block_repeats*[expand_dim*8],4,stride=2,normalization=norm),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*8)\n",
    "        )\n",
    "        \n",
    "        self.down4 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*8,residual_block_repeats*[expand_dim*16],4,stride=2,normalization=norm),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*8)\n",
    "        )\n",
    "        self.attn4 = CrossAttention(expand_dim*16,context_dim,expand_dim*16)\n",
    "        \n",
    "        self.down5 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*16,residual_block_repeats*[expand_dim*32],4,stride=2,normalization=norm),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*8)\n",
    "        )\n",
    "        self.attn5 = CrossAttention(expand_dim*32,context_dim,expand_dim*32)\n",
    "        \n",
    "        self.up1 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*32,residual_block_repeats*[expand_dim*16],4,stride=2,normalization=norm).transpose(),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*16)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*16,residual_block_repeats*[expand_dim*8],4,stride=2,normalization=norm).transpose(),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*8)\n",
    "        )\n",
    "        \n",
    "        self.up3 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*8,residual_block_repeats*[expand_dim*4],4,stride=2,normalization=norm).transpose(),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*4)\n",
    "        )\n",
    "        \n",
    "        self.up4 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*4,residual_block_repeats*[expand_dim*2],4,stride=2,normalization=norm).transpose(),\n",
    "            # EfficientSpatialChannelAttention(expand_dim*2)\n",
    "        )\n",
    "        \n",
    "        self.up5 = nn.Sequential(\n",
    "            ResidualBlock(expand_dim*2,residual_block_repeats*[expand_dim],4,stride=2,normalization=norm).transpose(),\n",
    "            # EfficientSpatialChannelAttention(expand_dim)\n",
    "        )\n",
    "        \n",
    "        self.final = ResidualBlock(\n",
    "            expand_dim,\n",
    "            [expand_dim,in_channels],\n",
    "            3,\n",
    "            normalization=norm\n",
    "        )\n",
    "\n",
    "    def forward(self,x, context : torch.Tensor, time):\n",
    "        if time.dim()<2:\n",
    "            time = time[:,None]\n",
    "        x_orig = x\n",
    "        # make it wider\n",
    "        time=time*5-2.5\n",
    "        \n",
    "        x=self.expand(x)\n",
    "        \n",
    "        d1 = self.down1(x)\n",
    "        # d1=self.attn1(d1,context,time)\n",
    "        \n",
    "        d2 = self.down2(d1)\n",
    "        # d2=self.attn2(d2,context,time)\n",
    "        \n",
    "        d3 = self.down3(d2)\n",
    "        \n",
    "        d4 = self.down4(d3)\n",
    "        d4 = self.attn4(d4,context,time)\n",
    "        \n",
    "        d5 = self.down5(d4)\n",
    "        d5 = self.attn5(d5,context,time)\n",
    "        \n",
    "        u1 = self.up1(d5)+d4\n",
    "        u2 = self.up2(u1)+d3\n",
    "        u3 = self.up3(u2)+d2\n",
    "        u4 = self.up4(u3)+d1\n",
    "        u5 = self.up5(u4)+x\n",
    "        \n",
    "        return self.final(u5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d176ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kemsekov_torch.train import load_best_checkpoint, load_last_checkpoint\n",
    "from kemsekov_torch.flow_matching import FlowMatching\n",
    "from kemsekov_torch.common_modules import wrap_submodules,CheapSequential\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "fm = FlowMatching()\n",
    "model = FlowMatchingModel(\n",
    "    3,\n",
    "    512,\n",
    "    expand_dim=128,\n",
    "    residual_block_repeats=1\n",
    ")\n",
    "path = 'runs/vae-natural/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930985eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip_emb import CLIPEmbedder\n",
    "c=CLIPEmbedder(device='cpu')\n",
    "embedds_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f505b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sample(\n",
    "    guidance,\n",
    "    reference_image,\n",
    "    images_count,\n",
    "    image_shape, \n",
    "    steps = 32,\n",
    "    churn_scale=0.001,\n",
    "    random_state=None,\n",
    "    device='cuda',\n",
    "    dtype=torch.bfloat16\n",
    "):\n",
    "    if random_state is not None:\n",
    "        g = torch.Generator(device)\n",
    "        g.manual_seed(random_state)\n",
    "    else:\n",
    "        g = None\n",
    "        \n",
    "    x0 = torch.randn([images_count,3]+list(image_shape),generator=g,device=device)\n",
    "    \n",
    "    if reference_image in embedds_cache:\n",
    "        print(\"cache\")\n",
    "        clip_emb=embedds_cache[reference_image].to(device)\n",
    "    else:\n",
    "        print(\"compute\")\n",
    "        clip_emb = c.image_to_embedding(reference_image)[None,:].to(device)\n",
    "        embedds_cache[reference_image]=clip_emb.cpu()\n",
    "        \n",
    "    context=clip_emb[[0]*images_count]\n",
    "    \n",
    "    m = model.to(device)\n",
    "    def run_model(xt,t):\n",
    "        pred_no_cls = m(xt,(context*0).to(dtype),t)\n",
    "        if guidance==0:\n",
    "            return pred_no_cls.float()\n",
    "        pred_cls =  m(xt,context,t)\n",
    "        total = pred_no_cls+guidance*(pred_cls-pred_no_cls)\n",
    "        return total\n",
    "\n",
    "    with torch.autocast(device,dtype=dtype):\n",
    "        sample = fm.sample(\n",
    "            run_model,\n",
    "            x0,\n",
    "            steps,\n",
    "            churn_scale=churn_scale,\n",
    "            device=device,\n",
    "        )\n",
    "        sample_dec = sample.sigmoid().to(device)\n",
    "    return sample_dec\n",
    "\n",
    "model = load_last_checkpoint(model,path).eval()\n",
    "images_count=4\n",
    "sample_dec = sample(\n",
    "    guidance=10,\n",
    "    reference_image='/home/vlad/Documents/data/cat/60.jpeg',\n",
    "    images_count=images_count,\n",
    "    image_shape=(256,256),\n",
    "    steps=32,\n",
    "    device='cuda',\n",
    "    # churn_scale=0.01,\n",
    "    # random_state=113\n",
    ")\n",
    "\n",
    "sq = int(images_count**0.5)\n",
    "plt.figure(figsize=(6,6))\n",
    "for i,v in enumerate(sample_dec):\n",
    "    plt.subplot(sq,sq,1+i)\n",
    "    plt.imshow(T.ToPILImage()(v))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038db105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog\n",
    "from tkinter import Canvas\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class ImageGeneratorApp:\n",
    "    def __init__(self, root, classes):\n",
    "        self.root = root\n",
    "        self.root.title(\"Image Generator\")\n",
    "\n",
    "        # Main frame split: left (canvas) and right (controls)\n",
    "        self.main_frame = tk.Frame(root)\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Left: image canvas with scrollbar\n",
    "        self.canvas_frame = tk.Frame(self.main_frame)\n",
    "        self.canvas_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.canvas = Canvas(self.canvas_frame, bg=\"white\")\n",
    "        self.scrollbar = ttk.Scrollbar(self.canvas_frame, orient=tk.HORIZONTAL, command=self.canvas.xview)\n",
    "        self.canvas.configure(xscrollcommand=self.scrollbar.set)\n",
    "\n",
    "        self.scrollbar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.images_container = tk.Frame(self.canvas)\n",
    "        self.image_container = self.canvas.create_window((0, 0), window=self.images_container, anchor=\"nw\")\n",
    "\n",
    "        # --- Right side (split into top controls and bottom scrollable classes) ---\n",
    "        self.controls_frame = tk.Frame(self.main_frame, padx=10, pady=10)\n",
    "        self.controls_frame.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        # Top fixed controls (guidance, count, size, buttons)\n",
    "        self.fixed_controls = tk.Frame(self.controls_frame, padx=5, pady=5)\n",
    "        self.fixed_controls.pack(side=tk.TOP, fill=tk.X)\n",
    "\n",
    "        length = 300\n",
    "\n",
    "        # Guidance\n",
    "        tk.Label(self.fixed_controls, text=\"Guidance\").pack(anchor=\"w\")\n",
    "        self.guidance_slider = tk.Scale(\n",
    "            self.fixed_controls, from_=0, to=5, resolution=0.1, orient=tk.HORIZONTAL, length=length\n",
    "        )\n",
    "        self.guidance_slider.pack(anchor=\"w\")\n",
    "        self.guidance_slider.set(1)\n",
    "\n",
    "        # Images count\n",
    "        tk.Label(self.fixed_controls, text=\"Images count\").pack(anchor=\"w\")\n",
    "        self.images_count = tk.Spinbox(self.fixed_controls, from_=1, to=20, width=5)\n",
    "        self.images_count.pack(anchor=\"w\")\n",
    "\n",
    "        # Width and Height (must be divisible by 32)\n",
    "        tk.Label(self.fixed_controls, text=\"Width\").pack(anchor=\"w\")\n",
    "        self.width_entry = tk.Spinbox(self.fixed_controls, from_=64, to=2048, increment=32, width=7)\n",
    "        self.width_entry.pack(anchor=\"w\")\n",
    "        self.width_entry.delete(0,\"end\")\n",
    "        self.width_entry.insert(0,256)\n",
    "\n",
    "\n",
    "        tk.Label(self.fixed_controls, text=\"Height\").pack(anchor=\"w\")\n",
    "        self.height_entry = tk.Spinbox(self.fixed_controls, from_=64, to=2048, increment=32, width=7)\n",
    "        self.height_entry.pack(anchor=\"w\")\n",
    "        self.height_entry.delete(0,\"end\")\n",
    "        self.height_entry.insert(0,256)\n",
    "        \n",
    "        tk.Label(self.fixed_controls, text=\"Steps\").pack(anchor=\"w\")\n",
    "        self.steps_entry = tk.Spinbox(self.fixed_controls, from_=1, to=64, increment=8, width=7)\n",
    "        self.steps_entry.pack(anchor=\"w\")\n",
    "        self.steps_entry.delete(0,\"end\")\n",
    "        self.steps_entry.insert(0,24)\n",
    "        \n",
    "        tk.Label(self.fixed_controls, text=\"Smoothness\").pack(anchor=\"w\")\n",
    "        self.smoothness_entry = tk.Spinbox(self.fixed_controls, from_=0, to=0.1, increment=0.001, width=7)\n",
    "        self.smoothness_entry.pack(anchor=\"w\")\n",
    "        self.smoothness_entry.delete(0,\"end\")\n",
    "        self.smoothness_entry.insert(0,0.001)\n",
    "\n",
    "        # Generate / Save buttons\n",
    "        self.generate_btn = tk.Button(self.fixed_controls, text=\"Generate\", command=self.generate_image)\n",
    "        self.generate_btn.pack(pady=5, fill=tk.X)\n",
    "\n",
    "        self.save_btn = tk.Button(self.fixed_controls, text=\"Save\", command=self.save_images)\n",
    "        self.save_btn.pack(pady=5, fill=tk.X)\n",
    "\n",
    "        # Scrollable class sliders\n",
    "        self.scroll_frame = tk.Frame(self.controls_frame)\n",
    "        self.scroll_frame.pack(side=tk.BOTTOM, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.controls_canvas = tk.Canvas(self.scroll_frame, width=350)\n",
    "        self.controls_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.controls_scrollbar = ttk.Scrollbar(\n",
    "            self.scroll_frame, orient=\"vertical\", command=self.controls_canvas.yview\n",
    "        )\n",
    "        self.controls_scrollbar.pack(side=tk.RIGHT, fill=\"y\")\n",
    "\n",
    "        self.controls_canvas.configure(yscrollcommand=self.controls_scrollbar.set)\n",
    "\n",
    "        self.classes_container = tk.Frame(self.controls_canvas, padx=10, pady=10)\n",
    "        self.controls_canvas.create_window((0, 0), window=self.classes_container, anchor=\"nw\")\n",
    "\n",
    "        def update_scrollregion(event):\n",
    "            self.controls_canvas.configure(scrollregion=self.controls_canvas.bbox(\"all\"))\n",
    "\n",
    "        self.classes_container.bind(\"<Configure>\", update_scrollregion)\n",
    "\n",
    "        # Add class sliders into scrollable frame\n",
    "        self.classes = classes\n",
    "        self.class_sliders = {}\n",
    "        for cls in classes:\n",
    "            label = tk.Label(self.classes_container, text=cls.capitalize())\n",
    "            label.pack(anchor=\"w\")\n",
    "            slider = tk.Scale(\n",
    "                self.classes_container, from_=0, to=1, resolution=0.01, orient=tk.HORIZONTAL, length=length\n",
    "            )\n",
    "            slider.pack(anchor=\"w\")\n",
    "            self.class_sliders[cls] = slider\n",
    "\n",
    "        # Keep references to images so they are not garbage-collected\n",
    "        self.generated_images = []\n",
    "        self.pil_images = []\n",
    "\n",
    "    def generate_image(self):\n",
    "        for widget in self.images_container.winfo_children():\n",
    "            widget.destroy()\n",
    "        self.generated_images.clear()\n",
    "        self.pil_images.clear()\n",
    "\n",
    "        class_values = {cls: slider.get() for cls, slider in self.class_sliders.items()}\n",
    "        classes_vector = [class_values[c] for c in self.classes]\n",
    "        guidance = self.guidance_slider.get()\n",
    "        count = int(self.images_count.get())\n",
    "        churn_scale = float(self.smoothness_entry.get())\n",
    "        steps = int(self.steps_entry.get())\n",
    "\n",
    "        # Width and Height (must be divisible by 32)\n",
    "        width = int(self.width_entry.get())\n",
    "        height = int(self.height_entry.get())\n",
    "        if width % 32 != 0 or height % 32 != 0:\n",
    "            print(\"⚠️ Width and height must be divisible by 32. Adjusting automatically.\")\n",
    "            width -= width % 32\n",
    "            height -= height % 32\n",
    "            self.width_entry.delete(0, tk.END)\n",
    "            self.width_entry.insert(0, str(width))\n",
    "            self.height_entry.delete(0, tk.END)\n",
    "            self.height_entry.insert(0, str(height))\n",
    "\n",
    "        # print(\"Generating images with:\")\n",
    "        # print(\"Classes:\", classes_vector)\n",
    "        # print(\"Guidance:\", guidance)\n",
    "        # print(\"Steps:\", steps)\n",
    "        # print(\"Churn_Scale:\", churn_scale)\n",
    "        # print(\"Count:\", count)\n",
    "        # print(\"Width:\", width, \"Height:\", height)\n",
    "\n",
    "        samples = sample(guidance,[classes_vector]*count,count,(width,height),steps,churn_scale)\n",
    "        for i,s in enumerate(samples):\n",
    "            img = T.ToPILImage()(s)\n",
    "            self.pil_images.append(img)\n",
    "\n",
    "            tk_img = ImageTk.PhotoImage(img)\n",
    "            self.generated_images.append(tk_img)\n",
    "\n",
    "            lbl = tk.Label(self.images_container, image=tk_img)\n",
    "            lbl.grid(row=0, column=i, padx=5, pady=5)\n",
    "\n",
    "        self.canvas.update_idletasks()\n",
    "        self.canvas.config(scrollregion=self.canvas.bbox(\"all\"))\n",
    "\n",
    "    def save_images(self):\n",
    "        if not self.pil_images:\n",
    "            print(\"No images to save!\")\n",
    "            return\n",
    "\n",
    "        folder = filedialog.askdirectory(title=\"Select folder to save images\")\n",
    "        if not folder:\n",
    "            return\n",
    "\n",
    "        for idx, img in enumerate(self.pil_images):\n",
    "            filepath = os.path.join(folder, f\"image_{idx+1}.png\")\n",
    "            img.save(filepath)\n",
    "            print(f\"Saved {filepath}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classes = model.classes\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.geometry(\"1600x1200\")\n",
    "    app = ImageGeneratorApp(root, classes)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
